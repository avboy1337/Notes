<!-- TOC -->

- [1. 多进程](#1-多进程)
- [2. 多线程](#2-多线程)
- [3. 协程（ Coroutine）](#3-协程-coroutine)

<!-- /TOC -->
# 1. 多进程

Linux下可以直接os.fork()，跨平台用multiprocessing.Process，如果需要大量子进程可以用multiprocessing.Pool，（multiprocessing通过Queue和Pipes提供了进程间通信机制）默认情况下池内线程数和CPU核心数一致，如果需要启动外部进程用subprocess，分布式进程用multiprocessing.managers。

# 2. 多线程

可以使用低级模块_thread或者高级模块threading（对_thread进行了封装）。线程锁用threading.Lock()。由于Python解释器中GIL的历史遗留问题，Python的多线程无法利用多个CPU核心（除非重写Python解释器或者利用Python的C拓展）。

ThreadLocal解决了参数在一个线程中各个函数之间互相传递的问题，一般用于每个线程绑定一个数据库连接，HTTP请求，用户身份信息等。

多进程稳定性高，但是进程调度消耗资源大，多线程消耗资源小一些，但是稳定性差（单个线程崩溃会导致整个进程崩溃）。在设计多任务时，需要考虑程序时计算密集型还是IO密集型。

# 3. 协程（ Coroutine）

在高并发环境中，如果采用多进程或者多线程方案，会导致进程线程数量过多，系统切换开销过大，性能严重下降。在这种情况下，异步IO（事件驱动模型）是最好的解决方案。异步IO可以通过协程实现，协程不需要进程线程切换，且不需要对资源进行上锁，所以效率会高很多。但是协程处于同一个线程内，所以无法利用多核CPU，可以采用多进程+协程的方式来利用多核CPU。

Python对协程的支持通过generator（生成器）实现。在generator中，可以通过for循环或者next()函数获取由yield语句返回的下一个值。Python的yield不但可以返回一个值，它还可以接收调用者发出的参数。

```python
def consumer():
    while True:
        n = yield "Yes!"
        print("Rec:{}".format(n))

def produce(c):
    c.send(None)  # 激活生成器
    print("Ret:{}".format(c.send(1)))
    c.close()

produce(consumer())
```

asyncio是Python 3.4版本引入的标准库，直接内置了对异步IO的支持。@asyncio.coroutine把一个generator标记为coroutine类型，我们从asyncio模块中直接获取一个EventLoop的引用，然后我们就把这个coroutine扔到EventLoop中执行，异步操作需要在coroutine中通过yield from完成；多个coroutine可以封装成一组Task然后并发执行。

```python
import asyncio

@asyncio.coroutine
def wget(host):
    print('wget %s...' % host)
    yield from asyncio.sleep(1)

loop = asyncio.get_event_loop()
tasks = [wget(host) for host in ['www.sina.com.cn', 'www.sohu.com', 'www.163.com']]
loop.run_until_complete(asyncio.wait(tasks))
loop.close()
```

Python从3.5版本开始为asyncio提供了async和await的新语法，把@asyncio.coroutine替换为async，把yield from替换为await。

asyncio实现了TCP、UDP、SSL等协议，另有aiohttp（基于asyncio实现的HTTP框架）可以用来开发异步IO的Web服务器。

